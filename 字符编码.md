# 字符编码

当谈论字符编码时，我们常常会听到一些术语，比如ASCII、GB2312、UTF-8等。这些术语代表了不同的字符编码方案，它们在计算机科学和软件开发中扮演着重要的角色。让我们逐一了解它们的含义以及它们之间的关系。

## ASCII

ASCII是一种最早的字符编码方案，最初由美国国家标准协会（ANSI）于1963年发布。ASCII编码使用7位来表示字符（最高位是0），共包括128个字符，其中包括英文字母、数字、标点符号和控制字符。ASCII编码被广泛应用于计算机系统中，是许多其他字符编码方案的基础。

## Unicode

然而，随着计算机技术的发展和全球化的兴起，ASCII编码的局限性变得越来越明显，因为它只能表示有限的字符集。因此，Unicode应运而生，旨在解决字符集的全球化问题。Unicode是一种字符编码方案，为世界上几乎每种语言中的每个字符提供了统一的字符编码。

> The Unicode Standard refers to the standard character set that represents all natural language characters. Unicode can encode up to roughly 1.1 million characters, allowing it to support all of the world’s languages and scripts in a single, universal standard.

Unicode可以编码大约110万个字符。

> Unicode 15.0 adds 4,489 characters, for a total of 149,186 characters. These additions include 2 new scripts, for a total of 161 scripts, along with 20 new emoji characters, and 4,193 CJK (Chinese, Japanese, and Korean) ideographs.

Unicode 15.0增加了4489个字符，总共149186个字符。

Unicode字符编码表：https://www.unicode.org/charts/index.html

Unicode基本汉字的编码范围位于十六进制的0x4E00至0x9FA5，即十进制的19968至40869，`U+4E00`表示`一`。
